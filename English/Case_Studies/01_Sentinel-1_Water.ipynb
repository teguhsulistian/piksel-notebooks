{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water detection with Sentinel-1\n",
    "\n",
    "**Adapted from https://github.com/digitalearthafrica/deafrica-sandbox-notebooks/blob/main/Real_world_examples/Radar_water_detection.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Over 40% of the worldâ€™s population lives within 100 km of the coastline.\n",
    "However, coastal environments are constantly changing, with erosion and coastal change presenting a major challenge to valuable coastal infrastructure and important ecological habitats.\n",
    "Updating data on the position of the coastline is essential for coastal managers to be able to identify and minimise the impacts of coastal change and erosion. \n",
    "The coastal regions are also home to many wetlands. Monitoring of water extent helps to understand and protect these dynamic and productive ecosystems.\n",
    "\n",
    "While coastlines and water extents can be mapped using optical data (demonstrated in the [Coastal Erosion notebook](../Real_world_examples/Coastal_erosion.ipynb)), these images can be strongly affected by the weather, especially through the presence of clouds, which obscure the land and water below.\n",
    "This can be a particular problem in cloudy regions or areas where clouds in wet season prevent optical satellites from taking clear images for many months of the year.\n",
    "\n",
    "Radar observations are largely unaffected by cloud cover.\n",
    "The two Sentinel-1 satellites, operated by ESA as part of the Copernicus program, provide all-weather observations every 6 to 12 days over Africa.\n",
    "By developing a process to classify the observed pixels as either water or land, it is possible to identify the shoreline and map the dynamic water extents using radar data.\n",
    "For more information, see the [Sentinel-1](../Datasets/Sentinel_1.ipynb) notebook.\n",
    "\n",
    "## Description\n",
    "\n",
    "In this example, we use data from the Sentinel-1 satellites to build a classifier that can determine whether a pixel is a water or land.\n",
    "Specifically, this notebook uses analysis-ready radar backscatter, which describes the strength of the signal received by the satellite.\n",
    "\n",
    "The notebook contains the following steps:\n",
    "\n",
    "1. Load Sentinel-1 backscatter data for an area of interest and visualize the returned data\n",
    "2. Applying speckle filter and converting the digital numbers to dB values for analysis\n",
    "3. Use histogram analysis to determine the threshold for water classification\n",
    "4. Design a classifier to distinguish land and water\n",
    "5. Apply the classifier to the area of interest and interpret the results\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from ipyleaflet import basemaps\n",
    "from odc.geo.geom import point\n",
    "from odc.stac import load\n",
    "from planetary_computer import sign_url\n",
    "from pystac_client import Client\n",
    "from scipy.ndimage import uniform_filter, variance\n",
    "from skimage.filters import threshold_minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and load data\n",
    "\n",
    "In this example, we're using Sentinel-1 radiometrically terrain corrected\n",
    "data from the Microsoft Planetary Computer. This is freely available, but\n",
    "you need to use a special Python function `sign_url` to authorise access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft Planetary Computer STAC Catalog URL\n",
    "catalog = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "\n",
    "# Create a STAC Client\n",
    "client = Client.open(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set study area name for outputs\n",
    "study_area = \"lake_toba\"\n",
    "\n",
    "# Create an aoi\n",
    "lat, lon = 2.7965, 98.6331\n",
    "aoi = point(lon, lat, crs=\"epsg:4326\")\n",
    "# Create a bounding box around the point\n",
    "region = aoi.buffer(0.2).to_crs(\"epsg:4326\")\n",
    "\n",
    "region.explore(tiles=basemaps.Esri.WorldImagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = \"2024-06/2024-07\"\n",
    "\n",
    "items = client.search(\n",
    "    collections=[\"sentinel-1-rtc\"],\n",
    "    intersects=region,\n",
    "    datetime=datetime,\n",
    ").item_collection()\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load(\n",
    "    items,\n",
    "    geopolygon=region,\n",
    "    measurements=[\"vv\", \"vh\"],\n",
    "    groupby=\"solar_day\",\n",
    "    patch_url=sign_url,\n",
    "    chunks={\"x\": 2048, \"y\": 2048}\n",
    ").compute()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "\n",
    "Do some simple plots of the data, so we know what we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VV polarisation\n",
    "data.isel(time=range(0,6)).vv.plot(cmap=\"Greys_r\", robust=True, col=\"time\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VH polarisation\n",
    "data.isel(time=range(0,6)).vh.plot(cmap=\"Greys_r\", robust=True, col=\"time\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backscatter measurements can be combined in visualization to highlight the different polarization signatures. \n",
    "For the RGB visualization below, the ratio between VH and VV is added as a third measurement band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VH/VV is a potentially useful third feature after VV and VH \n",
    "data['vh/vv'] = data.vh/data.vv\n",
    "\n",
    "# Median values are used to scale the measurements so they have a similar range for visualization\n",
    "medians = data.median(dim=[\"time\"])\n",
    "\n",
    "# Get scaled values so we can plot an RGB image for selected timesteps\n",
    "scaled = data / medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the plotting\n",
    "scaled.isel(time=range(0,6)).to_array().plot.imshow(robust=True, col=\"time\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply speckle filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radar observations appear speckly due to random interference of coherent signals from target scatters. \n",
    "The speckle noise can be reduced by averaging pixel values over an area or over time. \n",
    "However, averaging over a fixed window smoothes out real local spatial variation and leads to reduced spatial resolution.\n",
    "An adaptive approach that takes into account local homogeneity is therefore preferred.\n",
    "\n",
    "Below, we apply the Lee filter, one of the popular adaptive speckle filters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply lee filtering on S1 image \n",
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    da_notime = da.squeeze()\n",
    "    img = da_notime.values\n",
    "    img_mean = uniform_filter(img, size)\n",
    "    img_sqr_mean = uniform_filter(img**2, size)\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "\n",
    "    # Convert numpy array back to xarray, flipping the Y axis\n",
    "    output = xr.DataArray(img_output, dims=da_notime.dims, coords=da_notime.coords)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# The lee filter above doesn't handle null values\n",
    "# We therefore set null values to 0 before applying the filter\n",
    "valid = np.isfinite(data)\n",
    "masked = data.where(valid, 0)\n",
    "\n",
    "# Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "data[\"filtered_vv\"] = masked.vv.groupby(\"time\").map(lee_filter, size=7)\n",
    "data[\"filtered_vh\"] = masked.vh.groupby(\"time\").map(lee_filter, size=7)\n",
    "\n",
    "# Null pixels should remain null\n",
    "data['filtered_vv'] = data.filtered_vv.where(valid.vv)\n",
    "data['filtered_vh'] = data.filtered_vh.where(valid.vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images appear smoother after speckle filtering\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "data[\"vv\"].isel(time=3).plot(ax = ax[0],robust=True)\n",
    "data[\"filtered_vv\"].isel(time=3).plot(ax = ax[1],robust=True);\n",
    "ax[0].set_title('vv')\n",
    "ax[1].set_title('filtered vv')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the digital numbers to dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Sentinel-1 backscatter is provided as linear intensity, it is often useful to convert the backscatter to decible (dB) for analysis. \n",
    "Backscatter in dB unit has a more symmetric noise profile and less skewed value distribution for easier statistical evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['filtered_vv'] = 10 * np.log10(data.filtered_vv)\n",
    "data['filtered_vh'] = 10 * np.log10(data.filtered_vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram analysis for Sentinel-1\n",
    "\n",
    "Backscatter distributions are plotted below as histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 3))\n",
    "data.filtered_vh.plot.hist(bins=1000, label=\"VH filtered\")\n",
    "data.filtered_vv.plot.hist(bins=1000, label=\"VV filtered\",alpha=0.5)\n",
    "plt.xlim(-40,-1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"DN values in(dB)\")\n",
    "plt.title(\"Comparison of Lee filtered VH and VV polarisation bands\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and apply the classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram for VH backscatter shows a bimodal distribution with low values over water and high values over land.\n",
    "The VV histogram has multiple peaks and less obvious seperation between water and land.\n",
    "\n",
    "We therefore build a classifier based on VH backscatter. We choose a threshold to separate land and water: pixels with values below the threshold are water, and pixels with values above the threshold are not water (land).\n",
    "\n",
    "There are several ways to determine the threshold. \n",
    "Here, we use the `threshod_minimum` function implemented in the `skimage` package to determine the threshold from the *VH* histogram automatically.\n",
    "This method computes the histogram for all backscatter values, smooths it until there are only two maxima and find the minimum in between as the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv_no_nans = data.filtered_vv.values[~np.isnan(data.filtered_vv.values)]\n",
    "threshold_vv = threshold_minimum(vv_no_nans)\n",
    "\n",
    "print(threshold_vv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise threshold\n",
    "\n",
    "To check if our chosen threshold reasonably divides the two distributions, we can add the threshold to the histogram plots we made earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "data.filtered_vv.plot.hist(bins=1000, label=\"VH filtered\", color=\"gray\")\n",
    "plt.xlim(-40,-5)\n",
    "ax.axvspan(xmin=-40.0, xmax=threshold_vv, alpha=0.25, color=\"blue\", label=\"Water\")\n",
    "ax.axvspan(xmin=threshold_vv,\n",
    "           xmax=-5,\n",
    "           alpha=0.25,\n",
    "           color=\"green\",\n",
    "           label=\"Not Water\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"VH (dB)\")\n",
    "plt.title(\"Effect of the classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classifier\n",
    "\n",
    "This threshold is used to write a function to only return the pixels that are classified as water. The basic steps that the function will perform are:\n",
    "\n",
    "1. Find all pixels that have filtered values lower than the threshold; these are the `water` pixels.\n",
    "2. Return a data set containing the `water` pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S1_water_classifier(da, threshold=threshold_vv):\n",
    "    water_data_array = da < threshold\n",
    "    return water_data_array.to_dataset(name=\"s1_water\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the classifier function, we can apply it to the data. After running the classifier, we will able to view the classified data product by running `print(S1.water)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['water'] = S1_water_classifier(data.filtered_vv).s1_water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment with mean\n",
    "\n",
    "We can now view the image with our classification.\n",
    "The classifier returns either `True` or `False` for each pixel.\n",
    "To detect the boundaries of water features, we want to check which pixels are always water and which are always land.\n",
    "Conveniently, Python encodes `True = 1` and `False = 0`.\n",
    "\n",
    "If we plot the average classified pixel value, pixels that are always water will have an average value of `1` and pixels that are always land will have an average of `0`.\n",
    "Pixels that are sometimes water and sometimes land will have an average between these values. In this case study, these pixels are associated with seasonally inundated wetland areas. \n",
    "\n",
    "The following cell plots the average classified pixel value, or the frequency of water detection, over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean of each classified pixel value\n",
    "water_summary = (data.water.mean(dim='time') * 100).to_dataset(name=\"water_percentage\")\n",
    "water_summary[\"water_stdev\"] = data.water.std(dim='time') * 100\n",
    "\n",
    "water_summary.water_percentage.odc.explore(\n",
    "    cmap=\"RdBu\",\n",
    "    vmin=0, \n",
    "    max=100,\n",
    "    name=\"Water percentage\",\n",
    "    tiles=basemaps.Esri.WorldImagery,\n",
    "    attr=\"ESRI WorldImagery\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the selected threshold has done a good job of separating the water pixels (in blue) and land pixels (in red) as well as ephemeral water features in between. \n",
    "\n",
    "You should be able to see that the shoreline takes on a mix of values between `0` and `1`, highlighting pixels that are sometimes land and sometimes water.\n",
    "This is likely due to the effect of rising and falling tides, with some radar observations being captured at low tide, and others at high tide.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment with standard deviation\n",
    "\n",
    "Given that we've identified the shoreline as the pixels that are classified sometimes as land and sometimes as water, we can also see if the standard deviation of each pixel over time is a reasonable way to determine if a pixel is a shoreline or not.\n",
    "\n",
    "Similar to how we calculated and plotted the mean above, you can calculate and plot the standard deviation by using the `std` function in place of the `mean` function.\n",
    "\n",
    "If you'd like to see the results using a different colour scheme, you can also try substituting `cmap=\"Greys\"` or `cmap=\"Blues\"` in place of `cmap=\"viridis\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_summary.water_stdev.odc.explore(\n",
    "    tiles=basemaps.Esri.WorldImagery,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation we calculated above gives us an idea of how variable a pixel has been over the entire period of time that we looked at. From the image above, you should be able to see that the land and water pixels almost always have a standard deviation of `0`, meaning they didn't change over the time we sampled. The shoreline and wetlands however have a higher standard deviation, indicating that they change frequently between water and non-water.\n",
    "\n",
    "An important thing to recognise is that the standard deviation might not be able to detect the difference between noise, tides, and ongoing change, since a pixel that frequently alternates between land and water (noise) could have the same standard deviation as a pixel that is land for some time, then becomes water for the remaining time (ongoing change or tides)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "When you are done, return to the \"Analysis parameters\" section, modify some values (e.g. lat and lon) and rerun the analysis. You can use the interactive map in the \"View the selected location\" section to find new central latitude and longitude values by panning and zooming, and then clicking on the area you wish to extract location values for. You can also use Google maps to search for a location you know, then return the latitude and longitude values by clicking the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

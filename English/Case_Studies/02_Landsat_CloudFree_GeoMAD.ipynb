{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Free Mosaic and Geometric Median\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.config\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from datacube import Datacube\n",
    "from datacube.utils.masking import create_mask_value\n",
    "from datacube_compute import geomedian_with_mads\n",
    "from odc.geo.geom import point\n",
    "from odc.stac import configure_s3_access\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AWS\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "\n",
    "if \"AWS_NO_SIGN_REQUEST\" in os.environ:\n",
    "    del os.environ[\"AWS_NO_SIGN_REQUEST\"]\n",
    "\n",
    "configure_s3_access(requester_pays=True)\n",
    "\n",
    "dc = Datacube()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick a study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These coords are in the order Y then X, or Latitude then Longitude\n",
    "coords = -6.11, 105.42  # Krakatoa\n",
    "aoi_point = point(coords[1], coords[0], crs=\"EPSG:4326\")\n",
    "bbox = aoi_point.buffer(0.08).boundingbox\n",
    "\n",
    "landsat_stretch = dict(vmin=7500, vmax=12000)\n",
    "\n",
    "datetime = \"2024\"\n",
    "\n",
    "# Preview the area\n",
    "bbox.explore(zoom=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "This uses the Datacube library to handle loading of the actual data. The `dask_chunks` argument instructs the tool to use Dask\n",
    "to lazy-load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dc.find_datasets(\n",
    "    product=[\"ls9_c2l2_sr\"],\n",
    "    latitude=(bbox.bottom, bbox.top),\n",
    "    longitude=(bbox.left, bbox.right),\n",
    "    time=datetime,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(datasets)} Landsat datasets\")\n",
    "\n",
    "data = dc.load(\n",
    "    datasets=datasets,\n",
    "    measurements=[\"red\", \"green\", \"blue\", \"nir08\", \"pixel_qa\"],\n",
    "    output_crs=\"EPSG:32750\",\n",
    "    resolution=30,\n",
    "    time=\"2024\",\n",
    "    longitude=(bbox.left, bbox.right),\n",
    "    latitude=(bbox.bottom, bbox.top),\n",
    "    dask_chunks={\"time\": 1, \"x\": 1000, \"y\": 1000},\n",
    "    group_by=\"solar_day\",\n",
    "    driver=\"rio\",\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small subset so we can test cloud masking\n",
    "subset = data.isel(time=slice(0, 6))\n",
    "\n",
    "# Load the subset into memory\n",
    "subset = subset.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise data\n",
    "\n",
    "This step uses `matplotlib` to view data as a static image. It takes a longer time to\n",
    "run than previous steps, because it's actually loading the data to prepare the images.\n",
    "\n",
    "The `to_array()` function is a trick used to be able to visualise the data as a\n",
    "red, green, blue \"true colour\" image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(\n",
    "    col=\"time\", col_wrap=2, size=6, **landsat_stretch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_mask_landsat = {\n",
    "    \"cloud\": \"high_confidence\",\n",
    "    \"cloud_shadow\": \"high_confidence\",\n",
    "}\n",
    "\n",
    "mask_value, _ = create_mask_value(\n",
    "    datasets[0].product.measurements[\"qa_pixel\"].flags_definition,\n",
    "    **categories_to_mask_landsat,\n",
    ")\n",
    "\n",
    "mask = (subset.pixel_qa & mask_value) != 0\n",
    "\n",
    "# Plot the result, where white is clouds or cloud shadow and black is clear\n",
    "mask.plot.imshow(col=\"time\", col_wrap=2, size=6, cmap=\"gray_r\", vmin=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask the subset and preview the result\n",
    "masked_subset = subset.where(~mask)\n",
    "\n",
    "masked_subset[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(\n",
    "    col=\"time\", col_wrap=2, size=6, **landsat_stretch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a dask local cluster for parallel processing of the GeoMAD\n",
    "cluster = LocalCluster(\n",
    "    n_workers=2,\n",
    "    threads_per_worker=2,\n",
    "    memory_limit='10GB'\n",
    ")\n",
    "\n",
    "dashboard_url = cluster.dashboard_link\n",
    "port = urlparse(dashboard_url).port\n",
    "\n",
    "jupyterhub_user = os.environ.get('JUPYTERHUB_USER')\n",
    "dask.config.set(**{\n",
    "    \"distributed.dashboard.link\": f\"/user/{jupyterhub_user}/proxy/{port}/status\"\n",
    "})\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same process to the whole time series\n",
    "mask = (data.pixel_qa & mask_value) != 0\n",
    "masked_data = data.drop_vars(\"pixel_qa\").where(~mask)\n",
    "\n",
    "# Calculate the geomedian and MADs\n",
    "# Note, scale and offset values are specific to Landsat 9 C2 L2 SR data\n",
    "# See: https://www.usgs.gov/faqs/how-do-i-use-a-scale-factor-landsat-level-2-science-products\n",
    "geomad = geomedian_with_mads(\n",
    "    masked_data, scale=0.0000275, offset=-0.2, work_chunks=[1000, 1000]\n",
    ").compute()\n",
    "\n",
    "geomad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results\n",
    "geomad.odc.explore(**landsat_stretch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the variance (MADs)\n",
    "geomad.odc.explore(bands=[\"smad\", \"emad\", \"bcmad\"], robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up (close the dask client)\n",
    "# client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
